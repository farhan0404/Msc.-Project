# -*- coding: utf-8 -*-
"""Copy of MSc Project-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/102HmHQIYKRaSEP98sOGzMgDs8XBleG2u

# MSc Data Science - Farhan Ahmed Thottathi(THO21545214)

IMPORTING LIBRARIES
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.pipeline import Pipeline
from yellowbrick.regressor import prediction_error, residuals_plot
from sklearn.ensemble import GradientBoostingRegressor


url = 'https://raw.githubusercontent.com/farhan0404/Msc.-Project/main/Motor%20vehicle%20insurance%20data(processed.csv'
data = pd.read_csv(url)
print(data.head())

"""DATASET TRANSFORMATION PROCESS"""

import pandas as pd
from datetime import datetime
# Specify the correct date format
data['Date_birth'] = pd.to_datetime(data['Date_birth'], dayfirst=True)
data['Date_last_renewal'] = pd.to_datetime(data['Date_last_renewal'], dayfirst=True)
data['Date_driving_licence'] = pd.to_datetime(data['Date_driving_licence'], dayfirst=True)
# calculating the age at the last renewal date
data['Age'] = data.apply(
    lambda row: row['Date_last_renewal'].year - row['Date_birth'].year -
    ((row['Date_last_renewal'].month, row['Date_last_renewal'].day) <
     (row['Date_birth'].month, row['Date_birth'].day)), axis=1
)

# Now calculate the age at the last renewal date
data['Driving_since'] = data.apply(
    lambda row: row['Date_last_renewal'].year - row['Date_driving_licence'].year -
    ((row['Date_last_renewal'].month, row['Date_last_renewal'].day) <
     (row['Date_driving_licence'].month, row['Date_driving_licence'].day)), axis=1
)

data_new = data.drop(['Date_birth','Date_driving_licence','Date_start_contract'],axis=1)

data_new.head()

data_new.shape

data_new['Date_next_renewal'] = pd.to_datetime(data_new['Date_next_renewal'], dayfirst=True)

data_new['Date_lapse'] = pd.to_datetime(data_new['Date_lapse'], dayfirst=True)

data_new.info()

data_new.describe()

data_new['Distribution_channel'] = pd.to_numeric(data_new['Distribution_channel'], errors='coerce')

print(data_new.dtypes)

"""To visulaize in a heat map create a dataset"""

data_for_corr = data_new.drop(['Date_last_renewal','Date_next_renewal','Date_lapse'],axis =1)
data_for_corr.info()

data_for_corr = data_for_corr.drop(['Type_fuel'],axis=1)

correlation_matrix = data_for_corr.corr()

# mask to just show half of the map for more visualisation
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

# Set up the matplotlib figure
plt.figure(figsize=(15, 12))

# Draw the heatmap with the mask, without grid lines
sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='YlGn', cbar=True, linewidths=0)
# Remove the grid lines
plt.grid(False)
# Add a title to the heatmap
plt.title('Correlation Motor Vehicle Insurance', fontsize=20, fontweight='bold')
# Display the heatmap
plt.show()

plt.figure(figsize=(10, 8))  # Set the figure size (optional)
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', cbar=True)
plt.title('Correlation Heatmap')  # Add a title to the heatmap
plt.show()

plt.figure(figsize=(15,12))  # Adjust the figure size as necessary
sns.heatmap(correlation_matrix, annot=True, cmap='YlGn', cbar=True, linewidths=0, fmt=".2f", annot_kws={"size": 8})
plt.title('Correlation Heatmap')  # Optional: add a title
plt.show()

"""Premium Price against Age"""

fig,ax=plt.subplots(figsize=(12,6))
sns.lineplot(x=data_new.Age,y=data_new.Premium).set_title('Insurance Premium Price by Age')

#create a bin to plot age distribution in your data
pr_lab=['Low','Basic','Average','High','SuperHigh']
data_new['PremiumLabel']=pr_bins=pd.cut(data_new['Premium'],bins=5,labels=pr_lab,precision=0)

#Plot the age distribution in the dataset
sns.displot(x='Age',data=data_new,aspect=10/6,kde=True)

#using the same Bin for Age distribution plot a bar chart
fig,ax=plt.subplots(figsize=(12,6))
sns.countplot(x='PremiumLabel', data=data_new,ax=ax).set_title('Distribution of the Insurance Premium Price')

# Premium label Area and count
data_new.groupby(['PremiumLabel','Area'])['Area'].count()

plot = sns.barplot(data=data_new, x="Area", y= "Premium" ).set_title('Insurance Premium Price for Rural and Urban')

"""Plot age density based on premium"""

# Create age intervals of 10 years
data_new['Age_Group'] = pd.cut(data_new['Age'], bins=range(10, 110, 10), right=False, labels=[f'{i}-{i+10}' for i in range(10, 100, 10)])

# Now create the KDE plot
plot = sns.displot(data_new, x="Premium", hue="Age_Group", kind="kde", fill=True)

# Adjust the title of the plot
plot.fig.suptitle('Density Plot by Age Groups', fontsize=12, fontdict={"weight": "bold"})

# Show the plot
plt.show()

plot = sns.barplot(data=data_new, x="Second_driver", y= "Premium" ).set_title('Insurance Premium Price for Rural and Urban')

# Plot fuel-density against premium
plot= sns.displot(data_new, x="Premium", hue="Type_fuel", kind="kde", fill=True, )
plot.fig.suptitle('Density plot Type of fuel',
                  fontsize=12, fontdict={"weight": "bold"})

data_new.dtypes

# Now drop the attributes created for plotting
x = data_new.drop(['PremiumLabel','Age_Group'],axis=1)

x.tail()

x.shape

x.dtypes

x['Distribution_channel'].fillna(0, inplace=True)

# To address the missing values
missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

# To address the missing values in Type_fuel
x['premium_bin'] = x['Premium'].apply(lambda x: round(x,-2))
mode_fuel_per_bin = x.groupby('premium_bin')['Type_fuel'].agg(pd.Series.mode)

def fill_mode(row):
  if pd.isna(row['Type_fuel']):
        return mode_fuel_per_bin.get(row['premium_bin'], np.nan)
  return row['Type_fuel']

x['Type_fuel'] = x.apply(fill_mode, axis=1)

print(x)

missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

# Drop the attribute created in addressing the missing values in Type_fuel
x = x.drop(['premium_bin'],axis=1)

x.dtypes

# To address the missing values in legth create a pairplot between length and correlated features
sns.pairplot(data_for_corr,vars=['Length',"Weight","Cylinder_capacity","Value_vehicle"])
plt.show

# As there is a strong correlation between length and Cylinder_capacity, Weight and Value_vehicle we use linear regression model to fill in the missing values in Length.
from sklearn.linear_model import LinearRegression
predictors = ['Weight','Cylinder_capacity','Value_vehicle']
train_data = x[x['Length'].notna()]
predict_data = x[x["Length"].isna()]
regressor = LinearRegression()
regressor.fit(train_data[predictors],train_data['Length'])
predicted_values = regressor.predict(predict_data[predictors])
x.loc[x['Length'].isna(),'Length'] = predicted_values

# Check for missing values in data
missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns



# Define the target variable
target = 'Premium'

# Plotting each feature against 'Premium'
for column in x.columns:
    if column != target:
        plt.figure(figsize=(10, 6))

        if pd.api.types.is_numeric_dtype(x[column]):
            sns.scatterplot(data=x, x=column, y=target)
            plt.title(f'Scatter plot of {target} vs {column}')
        else:
            sns.boxplot(data=x, x=column, y=target)
            plt.title(f'Box plot of {target} vs {column}')

        plt.xlabel(column)
        plt.ylabel(target)
        plt.show()

x.dtypes

# change Type_fuel to numerical values by still mainting the categorical property's
x['Type_fuel'] = x['Type_fuel'].replace({'P': 0, 'D': 1})

# Print the updated DataFrame
print(x)

last = x['Date_last_renewal'].max()
print(last)

last1 = x['Date_next_renewal'].max()
print(last1)

last2 = x['Date_lapse'].max()
print(last2)

# Create a new attribute Lapse_to_next_renewal_days indicating the number of days of lapse till the next renewal date
import numpy as np
x['Lapse_to_next_renewal_days'] = np.where(x['Lapse']==1,(x['Date_lapse'] - x['Date_next_renewal']).dt.days,np.nan)

print(x.head(10))

print(x.head(25))

missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

#insert 0 to missing values in Lapse_to_next_renewal_days
x['Lapse_to_next_renewal_days'].fillna(0, inplace=True)

# drop the Date_lapse attribute from the dataset
x= x.drop(['Date_lapse'],axis=1)

missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

x.dtypes

# crrete Premium_lag_1 and Premium_lag_2 attributes from Premium to increase prediction power
x= x.sort_values(by=['ID','Date_next_renewal'])
x['Premium_lag_1'] = x.groupby('ID')['Premium'].shift(1)
x['Premium_lag_2'] = x.groupby('ID')['Premium'].shift(2)

x['Premium_lag_1'].fillna(0, inplace=True)
x['Premium_lag_2'].fillna(0, inplace=True)
# Extract Year and Month from renewal_date
x['Year'] = x['Date_next_renewal'].dt.year
x['Month'] = x['Date_next_renewal'].dt.month

missing_values_count = x.isnull().sum()

# To find only columns that have missing values
columns_with_missing_values = missing_values_count[missing_values_count > 0]

print(columns_with_missing_values)

x.dtypes

numerical_features = ['Driving_since','Age','Weight','Length','N_doors','Value_vehicle','Cylinder_capacity','Power','Cost_claims_year','R_Claims_history','N_claims_history','N_claims_year','Max_products','Max_policies','Policies_in_force','Seniority','Premium_lag_1','Premium_lag_2','Lapse_to_next_renewal_days','Premium']

correlation_matrix = x[numerical_features].corr()
# mask to just show half of the map for more visualisation
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

# Set up the matplotlib figure
plt.figure(figsize=(15, 12))

# Draw the heatmap with the mask, without grid lines
sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='YlGn', cbar=True, linewidths=0)
# Remove the grid lines
plt.grid(False)
# Add a title to the heatmap
plt.title('Correlation Motor Vehicle Insurance', fontsize=20, fontweight='bold')
# Display the heatmap
plt.show()

x.head()

x.dtypes

# as Year_matriculation is in YYYY format we create a new attribute  Year_last_renewal which is Date_last_renewal in YYYY format
x['Year_last_renewal'] = pd.to_datetime(x['Date_last_renewal']).dt.year

# Calcualte the vehicle age at the year of policy renewal
x['vehicle_age']= x['Year_last_renewal'] - x['Year_matriculation']

x.dtypes

x.head()

"""Plot Premium against all the features in the dataset

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns



# Define the target variable
target = 'Premium'

# Plotting each feature against 'Premium'
for column in x.columns:
    if column != target:
        plt.figure(figsize=(10, 6))

        if pd.api.types.is_numeric_dtype(x[column]):
            sns.scatterplot(data=x, x=column, y=target)
            plt.title(f'Scatter plot of {target} vs {column}')
        else:
            sns.boxplot(data=x, x=column, y=target)
            plt.title(f'Box plot of {target} vs {column}')

        plt.xlabel(column)
        plt.ylabel(target)
        plt.show()

x.dtypes

"""## AIM 1: PREDICT INSURANCE PREMIUM

"""

# identify the numerical variables
numerical_features = ['Driving_since','Age','Weight','Length','N_doors','Value_vehicle','Cylinder_capacity','Power','Cost_claims_year','R_Claims_history','N_claims_history','N_claims_year','Max_products','Max_policies','Policies_in_force','Seniority','Premium_lag_1','Premium_lag_2','Lapse_to_next_renewal_days','vehicle_age']

#identify the categorical Variable
categorical_features = ['Type_fuel','Distribution_channel','Second_driver','Type_risk','Payment','Area','Lapse']

# Split the data into Independent X variable and Target Y variable
y=x['Premium']
X=x.drop(['Premium','Date_next_renewal','Date_last_renewal','Year','Month','Year_last_renewal','Year_matriculation'],axis=1)

# Drop ID
X1 = X.drop(['ID'],axis=1)

X1.dtypes

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44, shuffle=True)

# Split the data into train and test for model training and evaluation
X1_train, X1_test, y1train, y1_test = train_test_split(X1, y, test_size=0.2, random_state=44, shuffle=True)

"""Scale the numerical data in the X1 variable"""

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

from sklearn.compose import ColumnTransformer
preprocessor = ColumnTransformer(transformers=[
    ('num', numerical_transformer, numerical_features),
    ('cat', categorical_transformer, categorical_features)
])

X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

X1_train = preprocessor.fit_transform(X1_train)
X1_test = preprocessor.transform(X1_test)

"""Models deployed before outliers where identified and removed"""

#TensorFlow Model
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(X1_train.shape[1],)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='mean_squared_error',
              metrics=['mae'])

history = model.fit(X1_train, y1train, epochs=100, batch_size=32, validation_data=(X1_test, y1_test), verbose=2)

# Evaluate the Model
test_loss, test_mae = model.evaluate(X1_test, y1_test, verbose=0)
print(f'Test MAE: {test_mae:.2f}')

# To evaluate the TensorFlow Model
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Predictions
y_train_pred = model.predict(X1_train).flatten()
y_test_pred = model.predict(X1_test).flatten()

# Calculate Evaluation Metrics
train_mae = mean_absolute_error(y1train, y_train_pred)
train_mse = mean_squared_error(y1train, y_train_pred)
train_r2 = r2_score(y1train, y_train_pred)

test_mae = mean_absolute_error(y1_test, y_test_pred)
test_mse = mean_squared_error(y1_test, y_test_pred)
test_r2 = r2_score(y1_test, y_test_pred)

# Print Metrics
print(f"Training MAE: {train_mae:.2f}")
print(f"Training MSE: {train_mse:.2f}")
print(f"Training R²: {train_r2:.2f}")
print(f"Testing MAE: {test_mae:.2f}")
print(f"Testing MSE: {test_mse:.2f}")
print(f"Testing R²: {test_r2:.2f}")

# Plot Actual vs Predicted
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.scatter(y1train, y_train_pred, alpha=0.7)
plt.plot([min(y1train), max(y1train)], [min(y1train), max(y1train)], 'k--')
plt.xlabel("Actual Premium")
plt.ylabel("Predicted Premium")
plt.title("Training: Actual vs Predicted")

plt.subplot(1, 2, 2)
plt.scatter(y1_test, y_test_pred, alpha=0.7)
plt.plot([min(y1_test), max(y1_test)], [min(y1_test), max(y1_test)], 'k--')
plt.xlabel("Actual Premium")
plt.ylabel("Predicted Premium")
plt.title("Testing: Actual vs Predicted")

plt.tight_layout()
plt.show()

# MLP model
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import GridSearchCV, train_test_split
mlp = MLPRegressor(hidden_layer_sizes=(128, 64, 32),
                   activation='relu',
                   max_iter=100,
                   random_state=42)

# Train the model
mlp.fit(X1_train, y1train)
'''param_grid = {
    'hidden_layer_sizes': [(50, 25), (64, 32), (100, 50), (100, 50, 25)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'alpha': [0.0001, 0.001],
    'learning_rate': ['constant', 'adaptive'],
    'batch_size': [64],
}
grid_search = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error', cv=2, verbose=1)
grid_search.fit(xtrain, ytrain)
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_'''
y_train_pred = mlp.predict(X1_train)
y_test_pred = mlp.predict(X1_test)
train_mae = mean_absolute_error(y1train, y_train_pred)
test_mae = mean_absolute_error(y1_test, y_test_pred)
train_mse = mean_squared_error(y1train,y_train_pred)
test_mse = mean_squared_error(y1_test,y_test_pred)
test_r2 = r2_score(y1_test,y_test_pred)
train_r2 = r2_score(y1train,y_train_pred)
print(f'Training MAE: {train_mae:.4f}')
print(f'Testing MAE: {test_mae:.4f}')
print(f'Training MSE: {train_mse:.4f}')
print(f'Testing MSE: {test_mse:.4f}')
print(f'Testing R²: {test_r2:.4f}')
print(f'Training R²: {train_r2:.4f}')

# XGB Model
from sklearn.linear_model import LinearRegression,Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
xgmodel0=XGBRegressor()
xgmodel0.fit(X1_train,y1train)
ypredtrain4=np.round(xgmodel0.predict(X1_train))
ypredtest4=np.round(xgmodel0.predict(X1_test))
print(r2_score(y1train,ypredtrain4))
print(r2_score(y1_test,ypredtest4))
#print(cross_val_score(xgmodel0,x1,y,cv=5,).mean())

# Hypertuning is not giving any better performance so it is avoided to save computational power
'''from sklearn.model_selection import GridSearchCV

estimator=XGBRegressor()
param_grid={'n_estimators':[50,100,150,200],'max_depth':[5,7,10],'gamma':[0,0.15,0.3,0.5,1],
            'learning_rate': [0.1, 0.01, 0.05], 'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}
grid3=GridSearchCV(estimator,param_grid,scoring="r2",cv=5)
grid3.fit(xtrain,ytrain)

print(grid3.best_params_)'''


ypredtrain4=xgmodel0.predict(X1_train)
ypredtest4=xgmodel0.predict(X1_test)



acc_xgb_Train = (r2_score(y1train,ypredtrain4))
print('R^2 Train:', acc_xgb_Train)

acc_xgb_Test = (r2_score(y1_test,ypredtest4))
print('R^2 Test:', acc_xgb_Test)

'''acc_xgb_CV = (cross_val_score(xgmodel,x1,y,cv=5,).mean())
print('R^2 CV:', acc_xgb_CV)'''


# other metrics
MAE_xgb_Train= mean_absolute_error(y1train,ypredtrain4)
print('MAE Train:',MAE_xgb_Train)
MSE_xgb_Train = mean_squared_error(y1train,ypredtrain4)
print('MSE Train:',MSE_xgb_Train)
MAE_xgb_Test= mean_absolute_error(y1_test,ypredtest4)
print('MAE:',MAE_xgb_Test)
MSE_xgb_Test = mean_squared_error(y1_test,ypredtest4)
print('MSE:',MSE_xgb_Test)
RMSE_xgb_Test = np.sqrt(mean_squared_error(y1_test,ypredtest4))
print('RMSE:', RMSE_xgb_Test)
MAPE_xgb_Test= (mean_absolute_percentage_error(y1_test,ypredtest4))
print('MAPE:',MAPE_xgb_Test)

# RandomForest Model
import time
import psutil
from sklearn.linear_model import LinearRegression,Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
#from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
# Record the start time
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error



rfmodel0=RandomForestRegressor(random_state=41)
rfmodel0.fit(X1_train,y1train)
ypredtrain2=rfmodel0.predict(X1_train)
ypredtest2=rfmodel0.predict(X1_test)
print(r2_score(y1train,ypredtrain2))
print(r2_score(y1_test,ypredtest2))
#print(cross_val_score(rfmodel0,x1,y,cv=5,).mean())
'''
from sklearn.model_selection import GridSearchCV
estimator=RandomForestRegressor(random_state=41)
param_grid={'n_estimators':[60, 220, 40]}
grid1=GridSearchCV(estimator,param_grid,scoring="r2",cv=2)
grid1.fit(X1_train,y1train)
print(grid1.best_params_)

rfmodel=grid1
rfmodel.fit(X1_train,y1train)
ypredtrain2=rfmodel.predict(X1_train)
ypredtest2=rfmodel.predict(X1_test)
print(r2_score(y1train,ypredtrain2))
print(r2_score(y1_test,ypredtest2))
#print(cross_val_score(rfmodel,x1,y,cv=5,).mean())'''



acc_RF_Train = (r2_score(y1train,ypredtrain2))
print('R^2 Train:', acc_RF_Train)

acc_RF_Test = (r2_score(y1_test,ypredtest2))
print('R^2 Test:', acc_RF_Test)

'''acc_RF_CV = cross_val_score(rfmodel,x1,y,cv=5,).mean()
print('R^2 CV:', acc_RF_CV)'''


# other metrics

MAE_RF_Train= mean_absolute_error(y1train,ypredtrain2)
print('MAE Train:',MAE_RF_Train)
MSE_RF_Train = mean_squared_error(y1train,ypredtrain2)
print('MSE Train:',MSE_RF_Train)
MAE_RF_Test= mean_absolute_error(y1_test,ypredtest2)
print('MAE:',MAE_RF_Test)
MSE_RF_Test = mean_squared_error(y1_test,ypredtest2)
print('MSE:',MSE_RF_Test)
RMSE_RF_Test = np.sqrt(mean_squared_error(y1_test,ypredtest2))
print('RMSE:', RMSE_RF_Test)
MAPE_RF_Test= (mean_absolute_percentage_error(y1_test,ypredtest2))
print('MAPE:',MAPE_RF_Test)

#print(cross_val_score(rfmodel0,X,y,cv=5,).mean())

#Now transform the whole dataset using the standardscaler for numerical values and OneHotEncoding for categorical values
X2 = preprocessor.fit_transform(X1)

#print(cross_val_score(rfmodel0,X1,y,cv=5,).mean())

y_pred = rfmodel0.predict(X2)

# Convert predictions and actual values to a Pandas DataFrame
actual_vs_pred = np.column_stack((y, y_pred))
df_result = pd.DataFrame(actual_vs_pred, columns=['Actual', 'Predicted'])

# Calculate error metrics
df_result['Error'] = df_result['Actual'] - df_result['Predicted']
df_result['Absolute_Error'] = np.abs(df_result['Error'])

# Calculate threshold for outliers (mean + 2 standard deviations)
threshold = df_result['Absolute_Error'].mean() + 2 * df_result['Absolute_Error'].std()
outliers = df_result[df_result['Absolute_Error'] > threshold]

print("Outliers Detected:")
print(outliers)

# Scatter Plot: Actual vs Predicted
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Actual', y='Predicted', data=df_result, label='Data Points')
sns.scatterplot(x='Actual', y='Predicted', data=outliers, color='red', label='Outliers')
plt.title('Actual vs Predicted Values')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()
plt.show()

# Error Plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x=df_result.index, y='Error', data=df_result, label='Error')
sns.scatterplot(x=outliers.index, y='Error', data=outliers, color='red', label='Outliers')
plt.axhline(0, color='black', linestyle='--')
plt.title('Errors')
plt.xlabel('Index')
plt.ylabel('Error')
plt.legend()
plt.show()

# Histogram of Absolute Errors
plt.figure(figsize=(10, 6))
sns.histplot(df_result['Absolute_Error'], bins=30, kde=True, color='blue')
plt.axvline(threshold, color='red', linestyle='--', label='Outlier Threshold')
plt.title('Distribution of Absolute Errors')
plt.xlabel('Absolute Error')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""Deploy Models after outliers are removed"""

# Get the indices of outliers
outlier_indices = outliers.index

# Remove outliers from X and y
X_clean = X.drop(outlier_indices)
y_clean = y.drop(outlier_indices)

# Split the data into train and test
X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=46, shuffle=True)

# Now preprocess the train and test dataset Numerical with standardscaler and Categorical with OneHotEncoder
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

import tensorflow as tf
model1 = tf.keras.Sequential([
    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)
])
model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='mean_squared_error',
              metrics=['mae'])

history = model1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=2)

# Evaluate the Model
test_loss, test_mae = model1.evaluate(X_test, y_test, verbose=0)
print(f'Test MAE: {test_mae:.2f}')

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Predictions
y_train_pred = model1.predict(X_train).flatten()
y_test_pred = model1.predict(X_test).flatten()

# Calculate Evaluation Metrics
train_mae = mean_absolute_error(y_train, y_train_pred)
train_mse = mean_squared_error(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

test_mae = mean_absolute_error(y_test, y_test_pred)
test_mse = mean_squared_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

# Print Metrics
print(f"Training MAE: {train_mae:.2f}")
print(f"Training MSE: {train_mse:.2f}")
print(f"Training R²: {train_r2:.2f}")
print(f"Testing MAE: {test_mae:.2f}")
print(f"Testing MSE: {test_mse:.2f}")
print(f"Testing R²: {test_r2:.2f}")

# Plot Actual vs Predicted
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.scatter(y_train, y_train_pred, alpha=0.7,c=y_train_pred, cmap='viridis')
plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], 'k--')
plt.xlabel("Actual Premium")
plt.ylabel("Predicted Premium")
plt.title("Training: Actual vs Predicted")

plt.subplot(1, 2, 2)
plt.scatter(y_test, y_test_pred, alpha=0.7,c=y_test_pred, cmap='viridis')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--')
plt.xlabel("Actual Premium")
plt.ylabel("Predicted Premium")
plt.title("Testing: Actual vs Predicted")

plt.tight_layout()
plt.show()

# MLP Model
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error,r2_score
from sklearn.model_selection import GridSearchCV, train_test_split
mlp = MLPRegressor(hidden_layer_sizes=(128, 64, 32),
                   activation='relu',
                   max_iter=100,
                   random_state=42)

# Train the model
mlp.fit(X_train, y_train)
'''param_grid = {
    'hidden_layer_sizes': [(50, 25), (64, 32), (100, 50), (100, 50, 25)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
    'alpha': [0.0001, 0.001],
    'learning_rate': ['constant', 'adaptive'],
    'batch_size': [64],
}
grid_search = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error', cv=2, verbose=1)
grid_search.fit(xtrain, ytrain)
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_'''
y_train_pred = mlp.predict(X_train)
y_test_pred = mlp.predict(X_test)
train_mae = mean_absolute_error(y_train, y_train_pred)
test_mae = mean_absolute_error(y_test, y_test_pred)
train_mse = mean_squared_error(y_train,y_train_pred)
test_mse = mean_squared_error(y_test,y_test_pred)
test_r2 = r2_score(y_test,y_test_pred)
train_r2 = r2_score(y_train,y_train_pred)
print(f'Training MAE: {train_mae:.4f}')
print(f'Testing MAE: {test_mae:.4f}')
print(f'Training MSE: {train_mse:.4f}')
print(f'Testing MSE: {test_mse:.4f}')
print(f'Testing R²: {test_r2:.4f}')
print(f'Training R²: {train_r2:.4f}')

# XGBoost Model
from sklearn.linear_model import LinearRegression,Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
xgmodel0=XGBRegressor()
xgmodel0.fit(X_train,y_train)
ypredtrain4=np.round(xgmodel0.predict(X_train))
ypredtest4=np.round(xgmodel0.predict(X_test))
print(r2_score(y_train,ypredtrain4))
print(r2_score(y_test,ypredtest4))

#X1 = preprocessor.fit_transform(X_clean)
#print(cross_val_score(xgmodel0,X1,y_clean,cv=3,).mean())
'''
from sklearn.model_selection import GridSearchCV

estimator=XGBRegressor()
param_grid={'n_estimators':[50,100,150,200],'max_depth':[5,7,10],'gamma':[0,0.15,0.3,0.5,1],
            'learning_rate': [0.1, 0.01, 0.05], 'subsample':[0.8,0.85,0.9]}
grid3=GridSearchCV(estimator,param_grid,scoring="r2",cv=5)
grid3.fit(X_train,y_train)

print(grid3.best_params_)


ypredtrain4=xgmodel0.predict(X_train)
ypredtest4=xgmodel0.predict(X_test)'''



acc_xgb_Train = (r2_score(y_train,ypredtrain4))
print('R^2 Train:', acc_xgb_Train)

acc_xgb_Test = (r2_score(y_test,ypredtest4))
print('R^2 Test:', acc_xgb_Test)

'''acc_xgb_CV = (cross_val_score(xgmodel,x1,y,cv=5,).mean())
print('R^2 CV:', acc_xgb_CV)'''


# other metrics
MAE_xgb_Train= mean_absolute_error(y_train,ypredtrain4)
print('MAE:',MAE_xgb_Train)
MSE_xgb_Train = mean_squared_error(y_train,ypredtrain4)
print('MSE:',MSE_xgb_Train)
RMSE_xgb_Train = np.sqrt(mean_squared_error(y_train,ypredtrain4))
print('RMSE:', RMSE_xgb_Train)
MAPE_xgb_Train= (mean_absolute_percentage_error(y_train,ypredtrain4))
print('MAPE:',MAPE_xgb_Train)

MAE_xgb_Test= mean_absolute_error(y_test,ypredtest4)
print('MAE:',MAE_xgb_Test)
MSE_xgb_Test = mean_squared_error(y_test,ypredtest4)
print('MSE:',MSE_xgb_Test)
RMSE_xgb_Test = np.sqrt(mean_squared_error(y_test,ypredtest4))
print('RMSE:', RMSE_xgb_Test)
MAPE_xgb_Test= (mean_absolute_percentage_error(y_test,ypredtest4))
print('MAPE:',MAPE_xgb_Test)

# RandomForest Model
from sklearn.linear_model import LinearRegression,Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
#from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
# Record the start time
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error



rfmodel0=RandomForestRegressor(random_state=41)
rfmodel0.fit(X_train,y_train)
ypredtrain2=rfmodel0.predict(X_train)
ypredtest2=rfmodel0.predict(X_test)
print(r2_score(y_train,ypredtrain2))
print(r2_score(y_test,ypredtest2))
'''X1 = preprocessor.fit_transform(X_clean)
print(cross_val_score(rfmodel0,X1,y_clean,cv=3,).mean())

from sklearn.model_selection import GridSearchCV
estimator=RandomForestRegressor(random_state=41)
param_grid={'n_estimators':[60, 220, 40]}
grid1=GridSearchCV(estimator,param_grid,scoring="r2",cv=3)
grid1.fit(X_train,y_train)
print(grid1.best_params_)

rfmodel=grid1
rfmodel.fit(X_train,y_train)
ypredtrain2=rfmodel.predict(X_train)
ypredtest2=rfmodel.predict(X_test)
print(r2_score(y_train,ypredtrain2))
print(r2_score(y_test,ypredtest2))

print(cross_val_score(rfmodel,X1,y_clean,cv=5,).mean())'''



acc_RF_Train = (r2_score(y_train,ypredtrain2))
print('R^2 Train:', acc_RF_Train)

acc_RF_Test = (r2_score(y_test,ypredtest2))
print('R^2 Test:', acc_RF_Test)

#acc_RF_CV = cross_val_score(rfmodel,X1,y_clean,cv=5,).mean()
#print('R^2 CV:', acc_RF_CV)


# other metrics
MAE_RF_Train= mean_absolute_error(y_train,ypredtrain2)
print('MAE:',MAE_RF_Train)
MSE_RF_Train = mean_squared_error(y_train,ypredtrain2)
print('MSE:',MSE_RF_Train)
RMSE_RF_Train = np.sqrt(mean_squared_error(y_train,ypredtrain2))
print('RMSE:', RMSE_RF_Train)
MAPE_RF_Train= (mean_absolute_percentage_error(y_train,ypredtrain2))
print('MAPE:',MAPE_RF_Train)

MAE_RF_Test= mean_absolute_error(y_test,ypredtest2)
print('MAE:',MAE_RF_Test)
MSE_RF_Test = mean_squared_error(y_test,ypredtest2)
print('MSE:',MSE_RF_Test)
RMSE_RF_Test = np.sqrt(mean_squared_error(y_test,ypredtest2))
print('RMSE:', RMSE_RF_Test)
MAPE_RF_Test= (mean_absolute_percentage_error(y_test,ypredtest2))
print('MAPE:',MAPE_RF_Test)

"""## AIM 2: Create a Fraud detection Model"""

x.dtypes

chance = x

print(chance)

# Create a attribute is_claim to mark 1 for Claim happening in the year
chance['is_claim'] = (chance['Cost_claims_year'] != 0).astype(int)

print(chance[['Cost_claims_year', 'is_claim']])

# Split the data into Y for target variable
Y_chance = chance['is_claim']

Y_chance.head(40)

chance.dtypes

# Drop the attributes from the independent variable which will overfit the model deployed
chance1 = chance.drop(['is_claim','ID','Cost_claims_year','N_claims_history','N_claims_year'],axis=1)

chance1.head()

# Drop the attributes with date format from the dependent variable
chance1 = chance1.drop(['Date_next_renewal','Date_last_renewal','Year','Month','Year_last_renewal','Year_matriculation'],axis=1)

chance1.dtypes

chance1.dtypes

#using RandomForestClassifier and feature importance Plot the feature importance inthe model
from sklearn.ensemble import RandomForestClassifier

# Assuming X are your predictors and y is the target (claim_amount)
model = RandomForestClassifier()
model.fit(chance1, Y_chance)

# Get feature importances
importances = model.feature_importances_

# Plotting feature importances
indices = np.argsort(importances)[::-1]
plt.figure(figsize=(10, 8))
plt.title('Feature Importances by RandomForest')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [chance1.columns[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

#Split the data into train and test
X_train1, X_test1, y_train1, y_test1 = train_test_split(chance1,Y_chance, test_size=0.2, random_state=44)
# using Minmax scale the data
from sklearn.preprocessing import MinMaxScaler

MM_scaler = MinMaxScaler()
MM_scaler.fit(X_train1)

X_train_scale = pd.DataFrame(MM_scaler.transform(X_train1),
                             index=X_train1.index,
                             columns=X_train1.columns)

X_test1 = pd.DataFrame(MM_scaler.transform(X_test1),
                             index=X_test1.index,
                             columns=X_test1.columns)

X_train_scale.min(axis=0)

X_train_scale.max(axis=0)

X_test.min(axis=0)

X_test.max(axis=0)

# using the Lasso Regression and SelectFromModel identify the features with zero variance coefficient
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel

# Establish the Lasso (L1) Regularisation model that will perform feature selection.
lasso = Lasso(alpha=5e-5, random_state=1, max_iter=int(1e+6)).fit(X_train_scale, y_train1)
model_L = SelectFromModel(lasso, prefit=True)

X_train_l1 = model_L.transform(X_train_scale)

selected_features = pd.DataFrame(model_L.inverse_transform(X_train_l1),
                                index=X_train_scale.index,
                                columns=X_train_scale.columns)

print(selected_features)

selected_columns = selected_features.columns[selected_features.var() != 0]

print(selected_columns)

#Drop the features with zero variance from train data
X_train_L2reg = selected_features.drop(selected_features.columns[selected_features.var() == 0], axis=1)

print(X_train_L2reg)

# Select only the features with non zero variance
X_valid_L2reg = X_test1[selected_columns]

# RandomForestClassifier Model
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
random_search = {'criterion': ['entropy', 'gini'],
               'max_depth': [2,3,4,5,6,7,10],
               'min_samples_leaf': [4, 6, 8],
               'min_samples_split': [5, 7,10],
               'n_estimators': [300]}

clf1 = RandomForestClassifier()
Randmodel = RandomizedSearchCV(estimator = clf1, param_distributions = random_search, n_iter = 10,
                               cv = 2, verbose= 1, random_state= 101, n_jobs = -1)
Randmodel.fit(X_train_L2reg,y_train1)

# Print the classification report on the X_Valid
y_pred12=Randmodel.predict(X_valid_L2reg)
print (classification_report(y_test1, y_pred12))

#Scale the whole dataset to retreive the classification report based on its prediction and actual
from sklearn.preprocessing import MinMaxScaler

MM_scaler = MinMaxScaler()
MM_scaler.fit(chance1)

X_chance1 = pd.DataFrame(MM_scaler.transform(chance1),
                             index=chance1.index,
                             columns=chance1.columns)
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel

# Establish the Lasso (L1) Regularisation model that will perform feature selection.
lasso = Lasso(alpha=5e-5, random_state=1, max_iter=int(1e+6)).fit(X_chance1, Y_chance)
modelL1 = SelectFromModel(lasso, prefit=True)

X_chance_l1 = modelL1.transform(X_chance1)

selected_features = pd.DataFrame(modelL1.inverse_transform(X_chance_l1),
                                index=X_chance1.index,
                                columns=X_chance1.columns)

print(selected_features)

selected_columns = selected_features.columns[selected_features.var() != 0]
X_chance_L1reg = selected_features.drop(selected_features.columns[selected_features.var() == 0], axis=1)

print(X_chance_L1reg)
print(selected_columns)

y_pred22=Randmodel.predict(X_chance_L1reg)
print (classification_report(Y_chance, y_pred22))

"""## AIM 3: Predict the Claim Amount Range"""

chance.dtypes

# Create a scatter plot Age Vs Cost_claims_year
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Premium', y='Cost_claims_year', data=chance, alpha=0.6, edgecolor=None)

plt.title('Age vs Claim Scatter Plot')
plt.xlabel('Age')
plt.ylabel('Cost_claims_year')
plt.show()

Claim_Data = chance

Claim_Data.dtypes

#Filter the Claim data to select the data for which claim has been made
import pandas as pd

# Create a mask where 'N_claims_year' is not equal to zero
mask = Claim_Data['is_claim'] != 0

# Filter X_Claim using the mask
Claim_Data_filtered = Claim_Data[mask]

# Create a scatter plot Premium Vs Cost_claims_year
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Premium', y='Cost_claims_year', data=Claim_Data_filtered, alpha=0.6, edgecolor=None)

plt.title('Premium vs Claim Scatter Plot')
plt.xlabel('Premium')
plt.ylabel('Cost_claims_year')
plt.show()

# Create the bins
bin_edges = pd.cut(Claim_Data_filtered['Cost_claims_year'], bins=5, retbins=True)[1]  # Returns bin edges as well
Claim_Data_filtered['claim_amount_bin'] = pd.cut(Claim_Data_filtered['Cost_claims_year'], bins=bin_edges, include_lowest=True)

# Generate labels based on these bins
bin_labels = [f"{int(bin_edges[i])} - {int(bin_edges[i+1])}" for i in range(len(bin_edges)-1)]
Claim_Data_filtered['claim_amount_bin_labels'] = pd.cut(Claim_Data_filtered['Cost_claims_year'], bins=bin_edges, labels=bin_labels, include_lowest=True)

# Plot the Bins created showing how many observations are there in each.
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=Claim_Data_filtered, x='claim_amount_bin_labels', palette='viridis')
plt.title('Distribution of Claim Amount Bins')
plt.xlabel('Claim Amount Ranges')
plt.ylabel('Count')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Add counts above the bars
for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center', fontsize=11, color='black', xytext=(0, 5),
                textcoords='offset points')

# Show the plot
plt.show()

print(Claim_Data_filtered)

# Extract 'Low' range entries

low_label = bin_labels[0]
low_entries = Claim_Data_filtered[Claim_Data_filtered['claim_amount_bin_labels'] == low_label]

# Print some of the filtered data to verify
print(low_entries.head())
print("Number of entries classified as 'Low':", len(low_entries))

print(low_entries.head())

# Drop Id and attributes with date format and isclaim and Claim amount Bins
Claim = low_entries.drop(['ID','Date_last_renewal','Date_next_renewal','Year_matriculation','Year','Month','Year_last_renewal','claim_amount_bin','claim_amount_bin_labels','is_claim'],axis=1)

#Create a Cost_claims_bin of 50 bins
Claim['Cost_claims_bin'] = pd.cut(Claim['Cost_claims_year'], bins=50, labels=False)

np.random.seed(0)
claim_amounts = np.random.exponential(scale=1000, size=1000)
df = pd.DataFrame({'claim_amount': claim_amounts})

# Descriptive statistics
desc_stats = Claim['Cost_claims_year'].describe()
skewness = Claim['Cost_claims_year'].skew()
kurtosis = Claim['Cost_claims_year'].kurtosis()

print("Descriptive Statistics:\n", desc_stats)
print("\nSkewness:", skewness)
print("Kurtosis:", kurtosis)

# Histogram
plt.figure(figsize=(10, 6))
sns.histplot(Claim['Cost_claims_year'], kde=True)
plt.title('Histogram of Claim Amounts')
plt.xlabel('Claim Amount')
plt.ylabel('Frequency')
plt.show()


# Density Plot
plt.figure(figsize=(10, 6))
sns.kdeplot(Claim['Cost_claims_year'], shade=True)
plt.title('Density Plot of Claim Amounts')
plt.xlabel('Claim Amount')
plt.ylabel('Density')
plt.show()

Xa = Claim.drop(['Cost_claims_year', 'Cost_claims_bin'], axis=1)
Ya = Claim['Cost_claims_bin']

#No Data augmentation
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import accuracy_score, classification_report
# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(Xa)

# Feature Selection using SelectFromModel with RandomForestRegressor
rf = RandomForestClassifier(random_state=42)
rf.fit(X_scaled, Ya)

# Use SelectFromModel to select important features
sfm = SelectFromModel(rf, threshold='mean')
sfm.fit(X_scaled, Ya)

# Get the selected features
selected_features = Xa.columns[sfm.get_support()]
X_selected = sfm.transform(X_scaled)

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X_selected, Ya, test_size=0.2, random_state=42)

# Train a RandomForestClassifier
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, Y_train)

# Predict the bins
Y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(Y_test, Y_pred)
report = classification_report(Y_test, Y_pred)

print("Selected features:", selected_features)
print("Accuracy:", accuracy)
print("Classification Report:\n", report)

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler
import numpy as np

# Assuming X and Y are defined from your dataset preprocessing

# Scale the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(Xa)

# Feature Selection using SelectFromModel with RandomForestClassifier
rf = RandomForestClassifier(random_state=42)
sfm = SelectFromModel(rf, threshold='mean')
sfm.fit(X_scaled, Ya)

# Get the selected features
selected_features = Xa.columns[sfm.get_support()]
X_selected = sfm.transform(X_scaled)

# Identify and separate very small classes
class_counts = Ya.value_counts()
small_classes = class_counts[class_counts < 2].index
small_class_mask = Ya.isin(small_classes)

X_small_classes = X_selected[small_class_mask]
Y_small_classes = Ya[small_class_mask]

X_filtered = X_selected[~small_class_mask]
Y_filtered = Ya[~small_class_mask]

# Apply SMOTE to handle imbalanced data
smote = SMOTE(random_state=42, k_neighbors=1)
X_resampled, Y_resampled = smote.fit_resample(X_filtered, Y_filtered)

# Apply RandomUnderSampler to balance the data
rus = RandomUnderSampler(random_state=42)
X_resampled, Y_resampled = rus.fit_resample(X_resampled, Y_resampled)

# Combine resampled data with very small classes
X_final = np.vstack((X_resampled, X_small_classes))
Y_final = np.hstack((Y_resampled, Y_small_classes))

# Split the final dataset into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=0.2, random_state=42)

# After Data Augmentation
# Train a RandomForestClassifier on the resampled data
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, Y_train)

# Predict the bins
Y_pred = rf_classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(Y_test, Y_pred)
report = classification_report(Y_test, Y_pred)

print("Selected features:", selected_features)
print("Accuracy:", accuracy)
print("Classification Report:\n", report)
